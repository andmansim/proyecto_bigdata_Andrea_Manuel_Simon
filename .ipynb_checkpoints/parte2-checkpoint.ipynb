{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dedbee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pyspark\n",
    "#no consigo q vaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abb0c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Cargar los datos en un datafra\n",
    "2. ¿Cuántas compañías diferentes aparecen en el fichero?\n",
    "3. ¿Cuántos pasajeros tienen de media los vuelos de cada compañía?\n",
    "4. Eliminaremos los registros duplicados por el campo “GEO Región”, manteniendo\n",
    "únicamente aquel con mayor número de pasajeros.\n",
    "5. Volcaremos los resultados de los dos puntos anteriores a un CSV\n",
    "'''\n",
    "'''\n",
    "df.toPandas() para pasar el código a pandas\n",
    "df.select(df.nombre columna).show() seleccionar columnas\n",
    "df.filter(df.nombre columna == valor).show() filtrar\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a6ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7de293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Cargar los datos en un datafra\n",
    "df = spark.read.csv('air_traffic_data.csv', header = True).show()#leer csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e940d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. ¿Cuántas compañías diferentes aparecen en el fichero?\n",
    "df.columns #Published Airline IATA Code, Operating Airline IATA Code, ns cuál de las dos es o si es ambas\n",
    "o = df.select(\"Operating Airline IATA Code\").distinct() #vamos los valores únicos \n",
    "list(o)\n",
    "print(o.show())\n",
    "p = df.select(\"Published Airline IATA Code\").distinct()\n",
    "list(p)\n",
    "print(p.show())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d2de3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. ¿Cuántos pasajeros tienen de media los vuelos de cada compañía?\n",
    "#tenemos q agrupar los datos de las distintas compañias y hacer la media\n",
    "mp = df.groupby('Published Airline IATA Code').avg() #hace la media de los string\n",
    "print(mp.show())\n",
    "mo = df.groupby('Operating Airline IATA Code').avg()\n",
    "print(mo.show())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47149ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Eliminaremos los registros duplicados por el campo “GEO Región”, manteniendo únicamente aquel con mayor número de pasajeros.\n",
    "#Primero ver los valores únicos de Geo, luego filtrar según estos y buscar su máximo, guardarlo en una lista\n",
    "o = df.select(\"GEO Region\").distinct()\n",
    "list(o)\n",
    "lista=[]\n",
    "for i in o:\n",
    "    a = df.filter(df['GEO Region'] == i)\n",
    "    a.show()\n",
    "    b = a.agg({'Passenger Count': 'max'})\n",
    "    b.show()\n",
    "    lista.append([i, b])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd7d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Volcaremos los resultados de los dos puntos anteriores a un CSV\n",
    "#Tenemos q ver cómo guardar losdatos del 3 y 4 para pasarlo a un csv\n",
    "df1 = spark.createDataFrame([[fila1], [fila2]], schema = [columnas])\n",
    "df1.write.csv('resultados.csv', header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
